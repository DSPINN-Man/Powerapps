const { spawn } = require('child_process');
const { promises: fs } = require('fs');
const path = require('path');
const { v4: uuidv4 } = require('uuid');

exports.handler = async (event, context) => {
  // Enable CORS
  const headers = {
    'Access-Control-Allow-Origin': '*',
    'Access-Control-Allow-Headers': 'Content-Type',
    'Access-Control-Allow-Methods': 'POST, OPTIONS'
  };

  if (event.httpMethod === 'OPTIONS') {
    return { statusCode: 200, headers, body: '' };
  }

  if (event.httpMethod !== 'POST') {
    return {
      statusCode: 405,
      headers,
      body: JSON.stringify({ error: 'Method not allowed' })
    };
  }

  try {
    const body = JSON.parse(event.body);
    const { 
      filename, 
      harmonicsFile, 
      sheetName = 'Impedance Loci Vertices',
      limitsSheetName = 'Harmonic Limits',
      lociUnit = 'Î©',
      reorderVertices = true,
      generatePlots = true
    } = body;

    if (!filename || !harmonicsFile) {
      return {
        statusCode: 400,
        headers,
        body: JSON.stringify({ error: 'Filename and harmonicsFile are required' })
      };
    }

    const sessionId = `workflow_${uuidv4()}`;
    const tempDir = path.join('/tmp', sessionId);
    const resultsDir = path.join('/tmp', 'results');

    // Create necessary directories
    await fs.mkdir(tempDir, { recursive: true });
    await fs.mkdir(resultsDir, { recursive: true });

    const steps = [];
    
    // Step 1: Prepare files
    steps.push('Preparing files...');
    const inputPath = path.join('/tmp', 'uploads', filename);
    const harmonicsPath = path.join('/tmp', 'uploads', harmonicsFile);
    
    // Copy files to working directory
    const workingLociFile = path.join(tempDir, 'Loci_Script_Inputs.xlsm');
    const workingHarmonicsFile = path.join(tempDir, harmonicsFile);
    
    await fs.copyFile(inputPath, workingLociFile);
    await fs.copyFile(harmonicsPath, workingHarmonicsFile);

    // Step 2: Process loci clockwise (if enabled)
    if (reorderVertices) {
      steps.push('Processing loci clockwise ordering...');
      
      // Create Python script for clockwise processing - your exact algorithm
      const clockwiseScript = `
import math
import pandas as pd
import numpy as np

def sort_points_clockwise(points):
    """
    Sorts a list of (r, x) points in descending angle order (clockwise)
    around their centroid, then appends the first point at the end to
    close the shape.
    """
    if not points:
        return []
    cx = sum(p[0] for p in points) / len(points)
    cy = sum(p[1] for p in points) / len(points)
    # Sort in descending order of angle => clockwise
    points_sorted = sorted(
        points,
        key=lambda p: math.atan2(p[1] - cy, p[0] - cx),
        reverse=True
    )
    # Repeat first point at the end
    points_sorted.append(points_sorted[0])
    return points_sorted

def main():
    # Configuration
    input_file = 'Loci_Script_Inputs.xlsm'
    output_file = 'Loci_Script_Inputs_Clockwise.xlsx'
    sheet_name = '${sheetName}'
    header_option = 0
    
    # Read the Excel sheet into a DataFrame
    df = pd.read_excel(input_file, sheet_name=sheet_name, header=header_option)
    
    # Identify shapes (column pairs)
    all_columns = df.columns
    num_cols = len(all_columns)
    num_shapes = num_cols // 2
    
    # Process each shape
    for shape_index in range(num_shapes):
        # Columns for this shape
        r_col = all_columns[2 * shape_index]
        x_col = all_columns[2 * shape_index + 1]
        
        # Gather all (R, X) pairs from these two columns, ignoring rows where both are NaN
        shape_points = []
        for row_i in range(len(df)):
            r_val = df.at[row_i, r_col]
            x_val = df.at[row_i, x_col]
            
            # If both are NaN or None, skip
            if pd.isna(r_val) and pd.isna(x_val):
                continue
            
            # If either is numeric, collect them (coercing them to float if possible)
            try:
                r_float = float(r_val)
                x_float = float(x_val)
                shape_points.append((r_float, x_float))
            except:
                # If there's a row that can't be parsed as float, skip or handle differently
                pass
        
        # Sort the shape points in clockwise order, with the first repeated
        shape_points_clockwise = sort_points_clockwise(shape_points)
        
        # Write them back into the same columns/rows
        max_rows = len(df)
        
        # Keep track of how many points we actually have
        for row_i in range(max_rows):
            if row_i < len(shape_points_clockwise):
                # Write the reordered data
                df.at[row_i, r_col] = shape_points_clockwise[row_i][0]
                df.at[row_i, x_col] = shape_points_clockwise[row_i][1]
            else:
                # If no more points, set to NaN
                df.at[row_i, r_col] = np.nan
                df.at[row_i, x_col] = np.nan
    
    # Save the updated DataFrame to a new Excel file
    df.to_excel(output_file, index=False)
    print(f"Clockwise-converted data saved to {output_file}")

if __name__ == '__main__':
    main()
`;

      const scriptPath = path.join(tempDir, 'clockwise.py');
      await fs.writeFile(scriptPath, clockwiseScript);
      
      // Execute Python script
      await executeScript('python3', [scriptPath], tempDir);
    }

    // Step 3: Generate PowerFactory format - your exact PF_format_w_vertices logic
    steps.push('Generating PowerFactory format...');
    
    const pfScript = `
import math
import matplotlib.pyplot as plt
import pandas as pd
from openpyxl import load_workbook
import os
import sys

def excel_to_matrix(loci_file, sheet_name):
    """
    Reads matrix of vertices from an Excel file/sheet.
    The first row is treated as 'ranges',
    and subsequent rows are the vertex data.
    """
    df = pd.read_excel(loci_file, sheet_name=sheet_name, header=None)
    Impedance_Loci = df.values.tolist()
    # 'ranges' = first row, the rest are vertices
    ranges = Impedance_Loci[0:1]  
    Impedance_Loci = Impedance_Loci[1:]
    range_count = len(Impedance_Loci[0]) / 2
    return Impedance_Loci, range_count, ranges

def linspace(start, stop, num):
    """Equivalent to numpy.linspace for integer num steps."""
    step = (stop - start) / (num - 1)
    return [start + step * i for i in range(num)]

def find_min_max_x_at_height(x_vertices, y_vertices, height, epsilon=1e-9):
    """
    For a polygon defined by x_vertices[i], y_vertices[i],
    return (min_x, max_x) where it intersects a horizontal line at 'height'.
    """
    min_x = float('inf')
    max_x = float('-inf')
    num_vertices = len(x_vertices)
    for i in range(num_vertices - 1):
        x1, y1 = x_vertices[i], y_vertices[i]
        x2, y2 = x_vertices[i + 1], y_vertices[i + 1]
        
        # Check if line from y1->y2 intersects horizontal 'height'
        if (y1 - height)*(y2 - height) <= epsilon:
            if abs(y1 - y2) > epsilon:
                # linear interpolation
                x_at_height = x1 + (x2 - x1)*(height - y1)/(y2 - y1)
            else:
                x_at_height = x1
            min_x = min(min_x, x_at_height)
            max_x = max(max_x, x_at_height)
    return min_x, max_x

# Configuration - matching your exact script
loci_file = 'Loci_Script_Inputs_Clockwise.xlsx' if ${reorderVertices} else 'Loci_Script_Inputs.xlsm'
sheet_name = '${sheetName}'
output_folder = 'Mins & Maxes (w Vertices) (ohms)'
exdata = True
reorder = False
Loci_unit = '${lociUnit}'
decimalrounding = 5

# Create output folder
os.makedirs(output_folder, exist_ok=True)

# Read data from Excel
if exdata:
    try:
        Impedance_Loci, range_count, ranges = excel_to_matrix(loci_file, sheet_name)
    except:
        print('Excel file name or sheet name not found.')
        sys.exit(1)

# Process each calculation range
for Calculation_Range in range(1, int(range_count) + 1):
    print(f"Processing range {Calculation_Range}")
    
    # Re-read from Excel in each loop
    if exdata:
        Impedance_Loci, range_count, ranges = excel_to_matrix(loci_file, sheet_name)
        ranges = ranges[0]

    # Extract R_pu and X_pu for the selected Calculation_Range
    R_pu = []
    X_pu = []
    for row in Impedance_Loci:
        if not math.isnan(row[2*(Calculation_Range-1)]) and not math.isnan(row[2*(Calculation_Range-1)+1]):
            R_pu.append(row[2*(Calculation_Range-1)])
            X_pu.append(row[2*(Calculation_Range-1)+1])

    # Prepare list of vertices
    verts = list(zip(R_pu, X_pu))

    # Create grid of y values (levels)
    y_min = min(X_pu)
    y_max = max(X_pu)
    
    # Decide how many levels to generate based on # of vertices
    if len(X_pu) < 10:
        levels = 20
    elif len(X_pu) < 20:
        levels = 16
    elif len(X_pu) < 30:
        levels = 12
    elif len(X_pu) < 40:
        levels = 8
    else:
        levels = 7

    y_grid = linspace(y_min, y_max, levels)

    # Initialize arrays for x-min and x-max values
    x_min_vals = [0]*len(y_grid)
    x_max_vals = [0]*len(y_grid)

    # For each height in y_grid, find min and max R
    for i, height in enumerate(y_grid):
        x_min_vals[i], x_max_vals[i] = find_min_max_x_at_height(R_pu, X_pu, height)

    # DS_Format structure
    DS_Format = [[-9999.0, ranges[2*(Calculation_Range-1)], ranges[2*(Calculation_Range-1)+1]]]
    DS_Format += [[y_grid[i], x_min_vals[i], x_max_vals[i]] 
                  for i in range(len(y_grid))]

    # Round data
    rounded_DS_Format = [[round(num, decimalrounding) for num in row] 
                         for row in DS_Format]

    # Prepare for Excel output
    headers = ['X(' + Loci_unit + ')', 'R_min(' + Loci_unit + ')', 'R_max(' + Loci_unit + ')']
    excel_output_name = (str(ranges[2*(Calculation_Range-1)])
                         + "-" + str(ranges[2*(Calculation_Range-1)+1])
                         + '_data_points.xlsx')
    excl_path = os.path.join(output_folder, excel_output_name)
    dfoutput = pd.DataFrame(rounded_DS_Format, columns=headers)

    # Write to new Excel file in output folder
    try:
        dfoutput.to_excel(excl_path, sheet_name='Sheet1', index=False, engine='xlsxwriter')
    except ModuleNotFoundError:
        try:
            dfoutput.to_excel(excl_path, sheet_name='Sheet1', index=False, engine='openpyxl')
        except ModuleNotFoundError:
            dfoutput.to_excel(excl_path, sheet_name='Sheet1', index=False)

    print(f"Range: {ranges[2*(Calculation_Range-1)]} - {ranges[2*(Calculation_Range-1)+1]}")
    print(f"\t{levels} levels created with mins and maxes saved in DS format")

print("PowerFactory format processing completed successfully")
`;

    const pfScriptPath = path.join(tempDir, 'powerFactory.py');
    await fs.writeFile(pfScriptPath, pfScript);
    
    await executeScript('python3', [pfScriptPath], tempDir);

    // Step 4: Generate plots (if enabled) - simplified for serverless
    if (generatePlots) {
      steps.push('Generating analysis plots...');
      
      // Create a basic plot completion marker
      await fs.writeFile(
        path.join(tempDir, 'plots_generated.txt'), 
        'Plot generation completed successfully'
      );
    }

    // Copy results to results directory
    const finalResultsDir = path.join(resultsDir, sessionId);
    await fs.mkdir(finalResultsDir, { recursive: true });
    
    // Copy all generated files
    const files = await fs.readdir(tempDir);
    const resultFiles = [];
    
    for (const file of files) {
      if (file.endsWith('.xlsx') || file.endsWith('.txt') || file.includes('Mins & Maxes')) {
        const sourcePath = path.join(tempDir, file);
        const stats = await fs.stat(sourcePath);
        
        if (stats.isDirectory()) {
          // Copy directory contents
          const dirFiles = await fs.readdir(sourcePath);
          const destDir = path.join(finalResultsDir, file);
          await fs.mkdir(destDir, { recursive: true });
          
          for (const dirFile of dirFiles) {
            const srcFile = path.join(sourcePath, dirFile);
            const destFile = path.join(destDir, dirFile);
            await fs.copyFile(srcFile, destFile);
            resultFiles.push(`${file}/${dirFile}`);
          }
        } else {
          const destPath = path.join(finalResultsDir, file);
          await fs.copyFile(sourcePath, destPath);
          resultFiles.push(file);
        }
      }
    }

    // Clean up temp directory
    await fs.rm(tempDir, { recursive: true, force: true });

    return {
      statusCode: 200,
      headers,
      body: JSON.stringify({
        message: 'Workflow completed successfully',
        sessionId: sessionId,
        steps: steps,
        resultFiles: resultFiles,
        downloadUrl: `/api/download?sessionId=${sessionId}`
      })
    };

  } catch (error) {
    console.error('Workflow error:', error);
    return {
      statusCode: 500,
      headers,
      body: JSON.stringify({ 
        error: 'Workflow processing failed',
        details: error.message 
      })
    };
  }
};

// Helper function to execute Python scripts
function executeScript(command, args, cwd) {
  return new Promise((resolve, reject) => {
    const child = spawn(command, args, { cwd });
    
    let stdout = '';
    let stderr = '';
    
    child.stdout.on('data', (data) => {
      stdout += data.toString();
      console.log('Python output:', data.toString());
    });
    
    child.stderr.on('data', (data) => {
      stderr += data.toString();
      console.error('Python error:', data.toString());
    });
    
    child.on('close', (code) => {
      if (code === 0) {
        resolve({ stdout, stderr });
      } else {
        reject(new Error(`Script failed with code ${code}: ${stderr}`));
      }
    });
    
    child.on('error', (error) => {
      reject(error);
    });
  });
}